{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688db3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/models/mreso/monarch/examples\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/models/mreso/monarch/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (1532023262.py, line 79)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdevice_id=\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected argument value expression\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monarch.tools import commands\n",
    "from monarch.actor import Actor, current_rank, endpoint\n",
    "from monarch.utils import setup_env_for_distributed\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# from slurm.utils_with_init import (\n",
    "from slurm.utils import (\n",
    "    get_appdef, \n",
    "    get_server_info, \n",
    "    create_proc_mesh,\n",
    ")\n",
    "\n",
    "os.environ[\"RUST_BACKTRACE\"] = \"full\"\n",
    "os.environ[\"RUST_LOG\"] = \"debug\"\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "class BarrierActor(Actor):\n",
    "    \"\"\"This Actor wraps the basic functionality from Torch's DDP example.\n",
    "\n",
    "    Conveniently, all of the methods we need are already laid out for us,\n",
    "    so we can just wrap them in the usual Actor endpoint semantic with some\n",
    "    light modifications.\n",
    "\n",
    "    Adapted from: https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "        self.rank = current_rank().rank\n",
    "        #self.local_rank = self.rank % 8  # Local GPU ID (0-7)\n",
    "        self.local_rank = int(self.rank % 8)  # Local GPU ID\n",
    "\n",
    "    def _rprint(self, msg):\n",
    "        \"\"\"Helper method to print with rank information.\"\"\"\n",
    "        print(f\"{self.rank=} {msg}\")\n",
    "\n",
    "    @endpoint\n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Initializing torch distributed\")\n",
    "        self._rprint(f\"{self.local_rank=}\")\n",
    "        # Set GPU device BEFORE dist.init_process_group\n",
    "        torch.cuda.set_device(self.local_rank)\n",
    "        self._rprint(f\"Set GPU device to {self.local_rank}\")\n",
    "\n",
    "\n",
    "        WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "        MASTER_ADDR = os.environ.get(\"MASTER_ADDR\", \"localhost\")\n",
    "        MASTER_PORT = os.environ.get(\"MASTER_PORT\", \"12355\")\n",
    "        RANK = int(os.environ.get(\"RANK\", \"0\"))\n",
    "        LOCAL_RANK = int(os.environ.get(\"LOCAL_RANK\", \"0\"))\n",
    "        print(f\"MASTER_ADDR: {MASTER_ADDR}, MASTER_PORT: {MASTER_PORT}, RANK: {RANK}\")\n",
    "        # initialize the process group\n",
    "        dist.init_process_group(\n",
    "                    backend=\"nccl\",\n",
    "                    init_method=f\"tcp://{MASTER_ADDR}:{MASTER_PORT}\",\n",
    "                    world_size=WORLD_SIZE,\n",
    "                    rank=RANK,\n",
    "                    device_id=LOCAL_RANK,\n",
    "                )\n",
    "        self._rprint(\"Finished initializing torch distributed\")\n",
    "\n",
    "    @endpoint\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Cleaning up torch distributed\")\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    @endpoint\n",
    "    async def demo_basic(self):\n",
    "        \"\"\"Run a basic DDP training example.\"\"\"\n",
    "        # self._rprint(f\"{os.environ['NCCL_DEBUG']=}\")\n",
    "        torch.cuda.set_device(self.local_rank)\n",
    "        self._rprint(\"Running basic DDP example\")\n",
    "        self._rprint(f\"{torch.cuda.device_count()=}\")\n",
    "        self._rprint(f\"{torch.cuda.current_device()=}\")\n",
    "        self._rprint(f\"{torch.cuda.get_device_name(0)=}\")\n",
    "        self._rprint(f\"{torch.cuda.is_initialized()=}\")\n",
    "        t = current_rank().rank * torch.ones(1).cuda()\n",
    "        torch.distributed.all_reduce(t)\n",
    "        self._rprint(f\"{t=}\")\n",
    "        self._rprint(\"Finished running basic DDP example\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_hosts = 2\n",
    "    appdef = await get_appdef(num_hosts)\n",
    "\n",
    "    appdef.roles[0].resource.gpu = 8\n",
    "\n",
    "    server_info = await get_server_info(appdef)\n",
    "\n",
    "    try:\n",
    "        print(\"CREATE PROC MESH\")\n",
    "        proc_mesh = await create_proc_mesh(num_hosts, appdef, server_info)\n",
    "        \n",
    "        await proc_mesh.logging_option(\n",
    "            stream_to_client=True,\n",
    "            aggregate_window_sec=None,\n",
    "        )\n",
    "\n",
    "        print(\"SPAWN ACTORS\")\n",
    "        barrier_actor = proc_mesh.spawn(\"barrier_actor\", BarrierActor)\n",
    "        print(\"SETUP ENV\")\n",
    "        await setup_env_for_distributed(proc_mesh)\n",
    "        print(\"SETUP CALL\")\n",
    "        await barrier_actor.setup.call()\n",
    "        print(\"BASIC DEMO CALL\")\n",
    "        await barrier_actor.demo_basic.call()\n",
    "        print(\"CLEAUP CALL\")\n",
    "        await barrier_actor.cleanup.call()\n",
    "\n",
    "        print(\"DDP example completed successfully!\")\n",
    "\n",
    "    finally:\n",
    "        commands.kill(f\"slurm:///{server_info.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcfc7-3561-43bd-9945-278fb488e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
